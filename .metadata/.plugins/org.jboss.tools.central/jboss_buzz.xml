<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>This week in JBoss (21st September 2018) - a mixed bag</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/RVNTUI0OaBQ/this-week-in-jboss-21st-september-2018-a-mixed-bag" /><category term="Camel" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="hibernate;" scheme="searchisko:content:tags" /><category term="jakarta ee" scheme="searchisko:content:tags" /><category term="JavaZone" scheme="searchisko:content:tags" /><category term="narayana" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="stm" scheme="searchisko:content:tags" /><author><name>Mark Little</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_21st_september_2018_a_mixed_bag</id><updated>2018-09-21T11:38:18Z</updated><published>2018-09-21T11:38:00Z</published><content type="html">&lt;!-- [DocumentBodyStart:97507437-318e-4240-84b7-0994a57ac4df] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;So in this week's entry we have a mixed bag of things to cover with no single focus area - the teams have been working across a number of areas.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OK so let's kick it off with a long entry from Michael Musgrove on the &lt;a class="jive-link-external-small" href="http://narayana.io/" rel="nofollow"&gt;Narayana&lt;/a&gt; team about &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/tips_on_how_to_evaluate_stm_implementations" rel="nofollow"&gt;how to evaluate STM implementations&lt;/a&gt;. As Mike says at the start of the article:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;"Software Transactional Memory (STM) is a way of providing transactional behaviour for threads operating on shared memory. The transaction is an atomic and isolated set of changes to memory such that prior to commit no other thread sees the memory updates and after commit the changes appear to take effect instantaneously so other threads never see partial updates but on abort all of the updates are discarded."&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;This is the first article in a series so if you're interested in transactions (and let's face it, who isn't?!) keep watching the &lt;a class="jive-link-external-small" href="http://jbossts.blogspot.com/" rel="nofollow"&gt;Narayana blog&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;There are a few entries on Hibernate to report on this week. The first from Guillaume talks about how to use &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/using_hibernate_orm_with_jdk_11" rel="nofollow"&gt;Hibernate ORM with JDK 11&lt;/a&gt;. Then Yoann announced the &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/triple_bugfix_release_for_hibernate_search_5_10_5_9_5_6" rel="nofollow"&gt;release of Hibernate Search 5.6, 5.9 and 5.10&lt;/a&gt;. And of course no editorial would be complete without referencing the regular &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/hibernate_community_newsletter_18_2018" rel="nofollow"&gt;Hibernate Community Newsletter&lt;/a&gt;!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Meanwhile Mr Camel himself, Claus Ibsen, has been to JavaZone and &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/my_trip_to_javazone_2018" rel="nofollow"&gt;has written a report&lt;/a&gt;, a photo from which is below!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;a href="https://developer.jboss.org/servlet/JiveServlet/showImage/38-6225-247599/IMG_7011.jpg"&gt;&lt;img alt="" class="image-1 jive-image" height="240" src="https://developer.jboss.org/servlet/JiveServlet/downloadImage/38-6225-247599/IMG_7011.jpg" style="height: auto;" width="320"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Finally for this week Cheng has written an article on &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/build_and_deploy_containerized_java_batch_applications_on_openshift" rel="nofollow"&gt;building and deploying containerized Java Batch Applications on OpenShift!&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OK that's it for now! See you next time.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:97507437-318e-4240-84b7-0994a57ac4df] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/RVNTUI0OaBQ" height="1" width="1" alt=""/&gt;</content><summary>So in this week's entry we have a mixed bag of things to cover with no single focus area - the teams have been working across a number of areas.   OK so let's kick it off with a long entry from Michael Musgrove on the Narayana team about how to evaluate STM implementations. As Mike says at the start of the article:   "Software Transactional Memory (STM) is a way of providing transactional behaviou...</summary><dc:creator>Mark Little</dc:creator><dc:date>2018-09-21T11:38:00Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2018/09/21/this-week-in-jboss-21st-september-2018-a-mixed-bag</feedburner:origLink></entry><entry><title>How to set up LDAP authentication for the Red Hat AMQ 7 management console</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/EAe_8mUdAOE/" /><category term="JBoss A-MQ" /><category term="Security" /><category term="amq" /><category term="Authentication" /><category term="hawtio" /><category term="ldap" /><category term="Red Hat AMQ" /><author><name>Elvadas Nono</name></author><id>https://developers.redhat.com/blog/?p=502287</id><updated>2018-09-21T11:00:14Z</updated><published>2018-09-21T11:00:14Z</published><content type="html">&lt;p&gt;This post is a continuation of the series on &lt;a href="https://developers.redhat.com/blog/2017/12/28/securing-amq7-brokers-ssl/"&gt;Red Hat AMQ 7 security topics&lt;/a&gt; for developers and ops people started by &lt;a href="https://developers.redhat.com/blog/author/mkcochran/"&gt;Mary Cochran&lt;/a&gt;.  We will see how to configure LDAP authentication on a &lt;a href="https://developers.redhat.com/products/amq/overview/"&gt;Red Hat AMQ 7&lt;/a&gt; broker instance. In order to do so, we will go perform the followings actions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Set up a simple LDAP server with a set of users and groups using &lt;a href="http://directory.apache.org/studio/"&gt;Apache Directory Studio&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Connect Red Hat AMQ 7 to LDAP using authentication providers.&lt;/li&gt; &lt;li&gt;Enable custom LDAP authorization policies in Red Hat AMQ 7.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span id="more-502287"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Set up the LDAP server&lt;/h2&gt; &lt;p&gt;In this tutorial, we will rely on Apache Directory Studio to quickly set up a simple LDAP server with the following structure:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/06/apachedirectorystudio-1.png"&gt;&lt;img class=" aligncenter wp-image-502357 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/apachedirectorystudio-1-1024x696.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/apachedirectorystudio-1-1024x696.png" alt="Apache Directory Studio screenshot" width="640" height="435" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/apachedirectorystudio-1-1024x696.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/apachedirectorystudio-1-300x204.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/apachedirectorystudio-1-768x522.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can use this &lt;a href="https://github.com/nelvadas/amq7_ldap_lab/blob/master/ldap.ldif"&gt;github.com/nelvadas/amq7_ldap_lab/blob/master/ldap.ldif&lt;/a&gt; file to reproduce the LDAP environment. From your root directory, import the &lt;code&gt;ldap.diff&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff.png"&gt;&lt;img class=" aligncenter wp-image-502377 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff-919x1024.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff-919x1024.png" alt="Importing the LDIF file" width="640" height="713" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff-919x1024.png 919w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff-269x300.png 269w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff-768x856.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/importldiff.png 1238w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Then, select the file you want to import,  select the &lt;strong&gt;Update existing entries&lt;/strong&gt; checkbox, and import the file.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile.png"&gt;&lt;img class=" aligncenter wp-image-502397 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile-1024x879.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile-1024x879.png" alt="Selecting the LDAP file" width="640" height="549" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile-1024x879.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile-300x258.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile-768x659.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/selectldifffile.png 1074w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For demonstration and simplicity purposes, all user passwords have been set to &lt;em&gt;redhat&lt;/em&gt;, for example:&lt;/p&gt; &lt;p&gt;&lt;em&gt;jdoe/redhat, enonowoguia/redhat&amp;#8230;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The Dind DN username and password to access LDAP server is &lt;em&gt;admin/secre&lt;/em&gt;t.&lt;/p&gt; &lt;p&gt;Once the LDAP server is set up and started, we can check the existing users with the following &lt;code&gt;ldapsearch&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;$ ldapsearch -H ldap://localhost:11389 -x -D "uid=admin,ou=system" -w "secret" -b "ou=Users,dc=example,dc=com" -LLL cn dn: cn=John+sn=Doe+uid=jdoe,ou=Users,dc=example,dc=com cn: John dn: cn=Elvadas NONO+uid=enonowoguia,ou=Users,dc=example,dc=com cn: elvadas nono dn: ou=Users,dc=example,dc=com dn: cn=demo+uid=demo,ou=Users,dc=example,dc=com cn: demo&lt;/pre&gt; &lt;p&gt;In the same context, we may want to display the different groups of  user &lt;em&gt;jdoe&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;$ ldapsearch -H ldap://localhost:11389 -x -D "uid=admin,ou=system" -w "secret" -b "ou=Groups,dc=example,dc=com" "(member=cn=John+sn=Doe+uid=jdoe,ou=Users,dc=example,dc=com)" -LL cn # extended LDIF # # LDAPv3 # base &amp;#60;ou=Groups,dc=example,dc=com&amp;#62; with scope subtree # filter: (member=cn=John+sn=Doe+uid=jdoe,ou=Users,dc=example,dc=com) # requesting: -LL cn # # Administrator, Groups, example.com dn: cn=Administrator,ou=Groups,dc=example,dc=com cn: Administrator # AMQGroup, Groups, example.com dn: cn=AMQGroup,ou=Groups,dc=example,dc=com cn: AMQGroup # search result search: 2 result: 0 Success # numResponses: 3 # numEntries: 2 &lt;/pre&gt; &lt;p&gt;At this point, we have set up our LDAP server and made sure it is up and running by using various &lt;code&gt;ldapsearch&lt;/code&gt; commands.&lt;/p&gt; &lt;p&gt;In the next section, we will configure Red Hat AMQ to authenticate users from LDAP and allow only users from AMQGroup to access the Management console and publish messages in queues.&lt;/p&gt; &lt;h2&gt;Start the Red Hat AMQ 7 Broker&lt;/h2&gt; &lt;p&gt;Red Hat AMQ 7 is a  lightweight, high-performance, robust messaging platform freely available for development use through Red Hat Developer Program.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/amq/download/"&gt;Download&lt;/a&gt; and unzip the last version on your computer:&lt;/p&gt; &lt;pre&gt;$ unzip ~/Downloads/amq-broker-7.1.1-bin.zip $ cd amq-broker-7.1.1/bin&lt;/pre&gt; &lt;p&gt;Create a broker instance with the default authentication mechanism:&lt;/p&gt; &lt;pre&gt;$ ./bin/artemis create ../../brokers/amq7-broker1 --name amq7-node1 --user admin --password admin --allow-anonymous Creating ActiveMQ Artemis instance at: /Users/enonowog/Documents/Missions/Blog/amq7ldap/brokers/amq7-broker1 Auto tuning journal ... done! Your system can make 16.67 writes per millisecond, your journal-buffer-timeout will be 59999 &lt;/pre&gt; &lt;p&gt;You can now start the broker by executing this command:&lt;/p&gt; &lt;pre&gt;"/Users/enonowog/Documents/Missions/Blog/amq7ldap/brokers/amq7-broker1/bin/artemis" run &lt;/pre&gt; &lt;p&gt;Or you can run the broker in the background using this command:&lt;/p&gt; &lt;pre&gt;"/Users/enonowog/Documents/Missions/Blog/amq7ldap/brokers/amq7-broker1/bin/artemis-service" start &lt;/pre&gt; &lt;p&gt;Start the broker as a background process.&lt;/p&gt; &lt;pre&gt;$ cd ../brokers $ "./amq7-broker1/bin/artemis-service" start Starting artemis-service artemis-service is now running (2804)&lt;/pre&gt; &lt;p&gt;Access the management console at http://localhost:8161/console/login:&lt;/p&gt; &lt;div id="attachment_502467" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsolewithdefaultadminloupe.png"&gt;&lt;img class=" aligncenter wp-image-502467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsolewithdefaultadminloupe-1024x379.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsolewithdefaultadminloupe-1024x379.png" alt="Accessing the AMQ 7 Management Console with the default Admin user" width="640" height="237" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsolewithdefaultadminloupe-1024x379.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsolewithdefaultadminloupe-300x111.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsolewithdefaultadminloupe-768x284.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Accessing the Red Hat AMQ 7 Management Console with the default Admin user&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the next section, we will see how to rely on the previously set up LDAP server to authenticate users.&lt;/p&gt; &lt;h2&gt;Configure LDAP authentication&lt;/h2&gt; &lt;p&gt;In order to enable LDAP authentication, the first step is to change the default &lt;code&gt;etc/login.config&lt;/code&gt; file to add the LDAP authentication provider.&lt;/p&gt; &lt;h3&gt;Add the LDAP authentication provider&lt;/h3&gt; &lt;p&gt;You can retrieve a working example &lt;a href="https://raw.githubusercontent.com/nelvadas/amq7_ldap_lab/master/login.config"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;$ cd brokers/amq7-broker1/etc/ MacBook-Pro-de-elvadas:etc enonowog$ cat &amp;#60;&amp;#60;EOF&amp;#62; login.config &amp;#62; activemq { &amp;#62; &amp;#62;   org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule required &amp;#62;      debug=true &amp;#62;      initialContextFactory=com.sun.jndi.ldap.LdapCtxFactory &amp;#62;      connectionURL="ldap://localhost:11389" &amp;#62;      connectionUsername="uid=admin,ou=system" &amp;#62;      connectionPassword=secret &amp;#62;      connectionProtocol=s &amp;#62;      authentication=simple &amp;#62;      userBase="ou=Users,dc=example,dc=com" &amp;#62;      userSearchMatching="(uid={0})" &amp;#62;      userSearchSubtree=true &amp;#62;      roleBase="ou=Groups,dc=example,dc=com" &amp;#62;      roleName=cn &amp;#62;      roleSearchMatching="(member={0})" &amp;#62;      roleSearchSubtree=false &amp;#62;      reload=true &amp;#62;   ; &amp;#62; &amp;#62; }; &amp;#62; EOF&lt;/pre&gt; &lt;p&gt;This file contains your LDAP configuration and states that the JAAS &lt;code&gt;LDAPLoginModule&lt;/code&gt; is required. Connection parameters such as the  LDAP URL and the Bind BD user details are provided.&lt;/p&gt; &lt;p&gt;For example, &lt;code&gt;UserBase="ou=Users,dc=example,dc=com"&lt;/code&gt;defines the organizationalUnit from which users will be found. And &lt;code&gt;userSearchMatching="(uid={0})"&lt;/code&gt; indicates users will be authenticated based on their UID.&lt;/p&gt; &lt;p&gt;&lt;code&gt;roleBase="ou=Groups,dc=example,dc=com"&lt;/code&gt; defines the base group in which user searches will be performed.&lt;/p&gt; &lt;h3&gt;Define the Hawtio console role&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;etc/artemis.profile&lt;/code&gt; file defines the LDAP group you want to grant access to the management console. In that file, replace the &lt;code&gt;-Dhawtio.role=amq&lt;/code&gt; with your LDAP group: &lt;code&gt;-Dhawtio.role=AMQGroup&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;# Java Opts  JAVA_ARGS=" -XX:+PrintClassHistogram -XX:+UseG1GC -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -Xms512M -Xmx2G -Dhawtio.realm=activemq -Dhawtio.offline="true" &lt;span style="color: red;"&gt;-Dhawtio.role=amq&lt;/span&gt; -Dhawtio.rolePrincipalClasses=org.apache.activemq.artemis.spi.core.security.jaas.RolePrincipal -Djolokia.policyLocation=${ARTEMIS_INSTANCE_URI}/etc/jolokia-access.xml -Djon.id=amq" &lt;/pre&gt; &lt;p&gt;You can do that by running the following command:&lt;/p&gt; &lt;pre&gt;sed -i.bak 's/hawtio.role=amq/hawtio.role=AMQGroup/g' artemis.profile&lt;/pre&gt; &lt;p&gt;You should now be able to log on to the management console using your LDAP credentials (&lt;em&gt;jdoe/redhat&lt;/em&gt;).&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsoleauthent.png"&gt;&lt;img class=" aligncenter wp-image-502497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsoleauthent-1024x347.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsoleauthent-1024x347.png" alt="LDAP management console authentification" width="640" height="217" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsoleauthent-1024x347.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsoleauthent-300x102.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/managementconsoleauthent-768x260.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Test and debug&lt;/h3&gt; &lt;p&gt;To see what is happening behind the scenes, you can enable debug logs on the &lt;code&gt;spi&lt;/code&gt; core security package.&lt;/p&gt; &lt;p&gt;Edit the &lt;code&gt;etc/logging.properties&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;Add the &lt;code&gt;org.apache.activemq.artemis.spi.core.security&lt;/code&gt; package to the root loggers.&lt;/p&gt; &lt;p&gt;Also add the DEBUG logging level for this package:&lt;/p&gt; &lt;p&gt;&lt;code&gt;logger.org.apache.activemq.artemis.spi.core.security.level=DEBUG&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Then restart your Red Hat AMQ instance.&lt;/p&gt; &lt;pre&gt;# Additional logger names to configure (root logger is always configured) 19 # Root logger option 20 loggers=...,org.apache.activemq.artemis.integration.bootstrap &lt;span style="color: red;"&gt;,org.apache.activemq.artemis.spi.core.security&lt;/span&gt; 21 # Root logger level 22 logger.level=INFO 23 # ActiveMQ Artemis logger levels 24 logger.org.apache.activemq.artemis.core.server.level=INFO 25 logger.org.apache.activemq.artemis.journal.level=INFO 26 logger.org.apache.activemq.artemis.utils.level=INFO 27 logger.org.apache.activemq.artemis.jms.level=INFO 28 logger.org.apache.activemq.artemis.integration.bootstrap.level=INFO &lt;span style="color: red;"&gt; 29 logger.org.apache.activemq.artemis.spi.core.security.level=DEBUG&lt;/span&gt; 30 logger.org.eclipse.jetty.level=WARN 31 # Root logger handlers 32 logger.handlers=FILE,CONSOLE&lt;/pre&gt; &lt;p&gt;You can see which roles are retrieved when the user tries to authenticate with LDAP:&lt;/p&gt; &lt;pre&gt;2018-06-15 17:26:18,824 INFO [org.apache.activemq.artemis] AMQ241001: HTTP Server started at http://localhost:8161 2018-06-15 17:26:18,825 INFO [org.apache.activemq.artemis] AMQ241002: Artemis Jolokia REST API available at http://localhost:8161/console/jolokia 2018-06-15 17:26:18,825 INFO [org.apache.activemq.artemis] AMQ241004: Artemis Console available at http://localhost:8161/console 2018-06-15 17:26:31,794 INFO [io.hawt.web.LoginServlet] hawtio login is using 1800 sec. HttpSession timeout 2018-06-15 17:26:31,814 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Create the LDAP initial context. 2018-06-15 17:26:31,826 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Get the user DN. 2018-06-15 17:26:31,826 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Looking for the user in LDAP with 2018-06-15 17:26:31,826 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] base DN: ou=Users,dc=example,dc=com 2018-06-15 17:26:31,827 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] filter: (uid=jdoe) 2018-06-15 17:26:31,830 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] LDAP returned a relative name: cn=John+sn=Doe+uid=jdoe 2018-06-15 17:26:31,831 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Using DN [cn=John+sn=Doe+uid=jdoe,ou=Users,dc=example,dc=com] for binding. 2018-06-15 17:26:31,831 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Binding the user. 2018-06-15 17:26:31,834 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] User cn=John+sn=Doe+uid=jdoe,ou=Users,dc=example,dc=com successfully bound. 2018-06-15 17:26:31,834 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Get user roles. 2018-06-15 17:26:31,834 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Looking for the user roles in LDAP with 2018-06-15 17:26:31,834 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] base DN: ou=Groups,dc=example,dc=com 2018-06-15 17:26:31,834 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] filter: (member=cn=John+sn=Doe+uid=jdoe,ou=Users,dc=example,dc=com) 2018-06-15 17:26:31,839 DEBUG [org.apache.activemq.artemis.spi.core.security.jaas.LDAPLoginModule] Roles [Administrator, AMQGroup] for user jdoe&lt;/pre&gt; &lt;p&gt;In this part, we defined authentication policies, but what about authorizations?&lt;/p&gt; &lt;h3&gt;Enable custom authorizations to LDAP groups&lt;/h3&gt; &lt;p&gt;To grant specific roles to your LDAP group, edit the &lt;code&gt;broker.xml&lt;/code&gt; configuration file and set specific permissions for your role:&lt;/p&gt; &lt;pre&gt;&amp;#60;security-settings&amp;#62; &amp;#60;security-setting match="#"&amp;#62; &amp;#60;permission type="createNonDurableQueue" roles="amq,AMQGroup"/&amp;#62; &amp;#60;permission type="deleteNonDurableQueue" roles="amq"/&amp;#62; &amp;#60;permission type="createDurableQueue" roles="amq,AMQGroup"/&amp;#62; &amp;#60;permission type="deleteDurableQueue" roles="amq"/&amp;#62; &amp;#60;permission type="createAddress" roles="amq,AMQGroup"/&amp;#62; &amp;#60;permission type="deleteAddress" roles="amq,AMQGroup"/&amp;#62; &amp;#60;permission type="consume" roles="amq,AMQGroup"/&amp;#62; &amp;#60;permission type="browse" roles="amq,AMQGroup"/&amp;#62; &amp;#60;permission type="send" roles="amq,AMQGroup"/&amp;#62; &amp;#60;!-- we need this otherwise ./artemis data imp wouldn't work --&amp;#62; &amp;#60;permission type="manage" roles="amq,AMQGroup"/&amp;#62; &amp;#60;/security-setting&amp;#62; &amp;#60;/security-settings&amp;#62; &lt;/pre&gt; &lt;p&gt;When the permissions are defined, they are automatically ingested by the running Red Hat AMQ instance. You can now produce a set of messages using the &lt;em&gt;jdoe&lt;/em&gt; user.&lt;/p&gt; &lt;pre&gt;&lt;span style="color: red;"&gt;$ ./artemis producer --url tcp://localhost:61616 --user jdoe --password redhat --destination queue://RH_DEV_BLOG --message-count 10&lt;/span&gt; Producer ActiveMQQueue[RH_DEV_BLOG], thread=0 Started to calculate elapsed time ... Producer ActiveMQQueue[RH_DEV_BLOG], thread=0 Produced: 10 messages Producer ActiveMQQueue[RH_DEV_BLOG], thread=0 Elapsed time in second : 0 s Producer ActiveMQQueue[RH_DEV_BLOG], thread=0 Elapsed time in milli second : 50 milli seconds &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this blog post, we saw how to set up a simple LDAP directory using Apache Directory Studio and configured LDAP authentication on Red Hat AMQ 7 for both messaging operations and the management console with custom authorization policies.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;linkname=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F21%2Fsetup-ldap-auth-amq-console%2F&amp;#38;title=How%20to%20set%20up%20LDAP%20authentication%20for%20the%20Red%20Hat%20AMQ%207%20management%20console" data-a2a-url="https://developers.redhat.com/blog/2018/09/21/setup-ldap-auth-amq-console/" data-a2a-title="How to set up LDAP authentication for the Red Hat AMQ 7 management console"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/21/setup-ldap-auth-amq-console/"&gt;How to set up LDAP authentication for the Red Hat AMQ 7 management console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/EAe_8mUdAOE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This post is a continuation of the series on Red Hat AMQ 7 security topics for developers and ops people started by Mary Cochran.  We will see how to configure LDAP authentication on a Red Hat AMQ 7 broker instance. In order to do so, we will go perform the followings actions: Set up a simple LDAP server [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/21/setup-ldap-auth-amq-console/"&gt;How to set up LDAP authentication for the Red Hat AMQ 7 management console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/09/21/setup-ldap-auth-amq-console/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">502287</post-id><dc:creator>Elvadas Nono</dc:creator><dc:date>2018-09-21T11:00:14Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/09/21/setup-ldap-auth-amq-console/</feedburner:origLink></entry><entry><title>Observe what your Istio mesh is doing with Kiali</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rzKe7r6X4Y0/" /><category term="Microservices" /><category term="Service Mesh" /><category term="istio" /><category term="Kiali" /><category term="microservices" /><category term="service mesh" /><author><name>Heiko Rupp</name></author><id>https://developers.redhat.com/blog/?p=519207</id><updated>2018-09-20T16:00:10Z</updated><published>2018-09-20T16:00:10Z</published><content type="html">&lt;p&gt;The &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;Istio service mesh&lt;/a&gt; is a powerful tool for building a service mesh. If you don&amp;#8217;t know about Istio yet, have a look at the &lt;a href="https://developers.redhat.com/blog/2018/03/06/introduction-istio-makes-mesh-things/"&gt;Introduction to Istio&lt;/a&gt; series of articles or download the ebook &lt;a href="https://developers.redhat.com/books/introducing-istio-service-mesh-microservices/"&gt;Introducing Istio Service Mesh for Microservices&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The power of Istio comes with the cost of some complexity at configuration and runtime. To help this, the &lt;a href="https://www.kiali.io/"&gt;Kiali&lt;/a&gt; project provides observability of the mesh and the services in the mesh. Kiali visualizes the mesh with its services and workloads. It indicates the health of the mesh and shows hints about applied configuration options. You can then drill in on individual services or settings to view details.&lt;/p&gt; &lt;p&gt;This post describes how to use Kiali to observe what the microservices in your Istio service mesh are doing, validate the Istio configuration, and see any issues.&lt;/p&gt; &lt;p&gt;&lt;span id="more-519207"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Visualizing an Istio service mesh&lt;/h2&gt; &lt;p&gt;Here&amp;#8217;s a Kiali graph view of an Istio service mesh:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46.png"&gt;&lt;img class=" aligncenter wp-image-519877 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46-1024x750.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46-1024x750.png" alt="Istio service mesh graph in Kiali" width="640" height="469" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46-1024x750.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46-300x220.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46-768x563.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.32.46.png 1436w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the above screenshot, you can see the mesh for the Istio Bookinfo demo. The &lt;em&gt;reviews&lt;/em&gt; application consists of three versioned workloads, and two of the workloads talk to the &lt;em&gt;ratings&lt;/em&gt; application.&lt;/p&gt; &lt;p&gt;The edge between the &lt;em&gt;productpage&lt;/em&gt; and &lt;em&gt;reviews:v1&lt;/em&gt; is highlighted (by clicking on it), which shows on the right side more detailed statistics about the request traffic and response time.&lt;/p&gt; &lt;h2&gt;Visualizing issues&lt;/h2&gt; &lt;p&gt;In the screenshot below you can see that there is something bad going on in the mesh. Parts of the graph show red and in the right sidebar, you can see that around one-third of the requests end up in an error.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31.png"&gt;&lt;img class=" aligncenter wp-image-519887 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31-1024x750.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31-1024x750.png" alt="detecting problems in the Istio service mesh" width="640" height="469" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31-1024x750.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31-300x220.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31-768x563.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.48.31.png 1436w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When you look closer at &lt;em&gt;ratings:v1&lt;/em&gt; and the &lt;em&gt;ratings&lt;/em&gt; triangle, you will see a y-shaped icon. This icon indicates that the &lt;em&gt;ratings&lt;/em&gt; service has an Istio VirtualService applied. From &lt;em&gt;reviews:v2,&lt;/em&gt; requests reach the &lt;em&gt;ratings:v1&lt;/em&gt; workload, but from &lt;em&gt;reviews:v3,&lt;/em&gt; the requests are failing.&lt;/p&gt; &lt;p&gt;Clicking on the triangle icon for the &lt;em&gt;ratings&lt;/em&gt; service and then clicking the link in the sidebar leads to the definition of the service. There, you can see that a virtual service is installed, which injects faults into the data stream. The Kiali screenshot below shows the details for a virtual service:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39.png"&gt;&lt;img class=" aligncenter wp-image-519897 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39-1024x750.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39-1024x750.png" alt="Kiali showing details of a virtual service" width="640" height="469" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39-1024x750.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39-300x220.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39-768x563.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-18-um-21.49.39.png 1436w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Kiali can also validate the Istio configuration. For example, Kiali shows a flag if the weight sum of the above HTTP routes does not add up to 100%.&lt;/p&gt; &lt;p&gt;Or, Kiali can flag when there is an issue with a configuration object. The details screen then shows the issue:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-19-um-11.36.30.png"&gt;&lt;img class=" aligncenter wp-image-520067 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-19-um-11.36.30.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-19-um-11.36.30-300x135.png" alt="Kiali highlighting a configuration issue in a virtual service" width="300" height="135" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-19-um-11.36.30-300x135.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-19-um-11.36.30-768x344.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Bildschirmfoto-2018-09-19-um-11.36.30.png 843w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Getting started with Kiali&lt;/h2&gt; &lt;p&gt;The Kiali documentation has &lt;a href="https://www.kiali.io/gettingstarted/"&gt;a page on getting started in OpenShift or plain Kubernetes&lt;/a&gt;. If you install upstream Istio, you can also choose to install Kiali with it. Have a look at the &lt;a href="https://istio.io/docs/reference/config/installation-options/"&gt;configuration options for Helm&lt;/a&gt; or &lt;a href="https://istio.io/docs/setup/kubernetes/ansible-install/#customization-with-ansible"&gt;customization with Ansible&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Logging in to Kiali (for now) is done using &lt;em&gt;admin/admin&lt;/em&gt;.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Contributing to Kiali&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Kiali is open source and released under the Apache V2.0 license. The &lt;a href="https://github.com/kiali"&gt;source code lives on GitHub&lt;/a&gt; and any contributions are welcome. Please have a look at the &lt;a href="https://github.com/kiali/kiali/blob/master/README.adoc#contributing"&gt;contributing section of the README&lt;/a&gt; before you get started.&lt;/p&gt; &lt;h2&gt;More information&lt;/h2&gt; &lt;p&gt;The Kiali web page and GitHub pages are a good start. Kiali also has a &lt;a href="https://medium.com/kialiproject"&gt;blog&lt;/a&gt; and a &lt;a href="https://www.youtube.com/channel/UCcm2NzDN_UCZKk2yYmOpc5w"&gt;YouTube channel&lt;/a&gt; that features the recording of the end-of-sprint demos. And last but not least, there is &lt;a href="https://twitter.com/KialiProject"&gt;Twitter&lt;/a&gt;. &lt;img src="https://s.w.org/images/core/emoji/2.4/72x72/1f642.png" alt="&#x1f642;" class="wp-smiley" style="height: 1em; max-height: 1em;" /&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;linkname=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F20%2Fistio-mesh-visibility-with-kiali%2F&amp;#38;title=Observe%20what%20your%20Istio%20mesh%20is%20doing%20with%20Kiali" data-a2a-url="https://developers.redhat.com/blog/2018/09/20/istio-mesh-visibility-with-kiali/" data-a2a-title="Observe what your Istio mesh is doing with Kiali"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/20/istio-mesh-visibility-with-kiali/"&gt;Observe what your Istio mesh is doing with Kiali&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rzKe7r6X4Y0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Istio service mesh is a powerful tool for building a service mesh. If you don&amp;#8217;t know about Istio yet, have a look at the Introduction to Istio series of articles or download the ebook Introducing Istio Service Mesh for Microservices. The power of Istio comes with the cost of some complexity at configuration and runtime. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/20/istio-mesh-visibility-with-kiali/"&gt;Observe what your Istio mesh is doing with Kiali&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/09/20/istio-mesh-visibility-with-kiali/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">519207</post-id><dc:creator>Heiko Rupp</dc:creator><dc:date>2018-09-20T16:00:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/09/20/istio-mesh-visibility-with-kiali/</feedburner:origLink></entry><entry><title>Troubleshooting FDB table wrapping in Open vSwitch</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/4wxxeyKr8eA/" /><category term="Cloud" /><category term="OpenStack" /><category term="Red Hat Enterprise Linux" /><category term="RHEV" /><category term="cloud networking" /><category term="FDB" /><category term="FDB wrapping" /><category term="forwarding database table" /><category term="network function virtualization" /><category term="networking" /><category term="NFV" /><category term="Open vSwitch" /><category term="ovs-dpdk" /><category term="performance" /><category term="performance tuning" /><category term="virtual networking" /><author><name>Eelco Chaudron</name></author><id>https://developers.redhat.com/blog/?p=519187</id><updated>2018-09-19T11:00:00Z</updated><published>2018-09-19T11:00:00Z</published><content type="html">&lt;p&gt;When most people deploy an &lt;a href="https://developers.redhat.com/blog/tag/open-vswitch/"&gt;Open vSwitch&lt;/a&gt; configuration for virtual networking using the NORMAL rule, that is, using L2 learning, they do not think about configuring the size of the &lt;strong&gt;F&lt;/strong&gt;orwarding &lt;strong&gt;D&lt;/strong&gt;ata&lt;strong&gt;B&lt;/strong&gt;ase (&lt;strong&gt;FDB&lt;/strong&gt;).&lt;/p&gt; &lt;p&gt;When hardware-based switches are used, the FDB size is generally rather large and the large FDB size is a key selling point. However for Open vSwitch, the default FDB value is rather small, for example, in version 2.9 and earlier it is only 2K entries. Starting with version 2.10 the FDB size was increased to 8K entries. Note that for Open vSwitch, each bridge has its own FDB table for which the size is individually configurable.&lt;/p&gt; &lt;p&gt;This blog explains the effects of configuring too small an FDB table, how to identify which bridge is suffering from too small an FDB table, and how to configure the FDB table size appropriately.&lt;/p&gt; &lt;p&gt;&lt;span id="more-519187"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="what-are-the-effects-of-a-to-small-comfigured-fdb-table"&gt;Effects of too small an FDB table&lt;/h2&gt; &lt;p&gt;When the FDB table is full and a new entry needs to be added, an older entry is removed to make room for the new one&lt;sup&gt;1&lt;/sup&gt;. This is called &lt;em&gt;FDB wrapping&lt;/em&gt;. If a packet is then received from the MAC address whose entry was removed, another entry is removed to make room, and the source MAC address of the packet will be re-added.&lt;/p&gt; &lt;p&gt;When more MAC addresses exist in the network than can be held in the configured FDB table size and all the MAC addresses are seen frequently, a lot of ping/ponging in the table can happen.&lt;/p&gt; &lt;p&gt;The more ping/ponging there is, the more CPU resources are needed to maintain the table. In addition, if traffic is received from evicted MAC addresses, the traffic is flooded out of all ports.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; The algorithm for removing older entries in Open vSwitch is as follows. On the specific bridge, the port with the most FDB entries is found and the oldest entry is removed.&lt;/p&gt;&lt;/blockquote&gt; &lt;h2&gt;Open vSwitch–specific manifestations of too small an FDB table&lt;/h2&gt; &lt;p&gt;In addition to the FDB table updates, Open vSwitch also has to clean up the flow table when an FDB entry is removed. This is done by the Open vSwitch &lt;em&gt;revalidator&lt;/em&gt; thread. Because this flow table cleanup takes quite a bit of CPU cycles, the first indication you might have of an FDB table wrapping issue is a high revalidator thread utilization. The following example shows a high revalidator thread utilization of around 83% (deduced by adding the percentages shown in the CPU% column) in an idle system:&lt;/p&gt; &lt;pre&gt;$ pidstat -t -p `pidof ovs-vswitchd` 1 | grep -E "UID|revalidator" 07:37:56 AM UID TGID TID %usr %system %guest %CPU CPU Command 07:37:57 AM 995 - 188565 5.00 5.00 0.00 10.00 2 |__revalidator110 07:37:57 AM 995 - 188566 6.00 4.00 0.00 10.00 2 |__revalidator111 07:37:57 AM 995 - 188567 6.00 5.00 0.00 11.00 2 |__revalidator112 07:37:57 AM 995 - 188568 5.00 5.00 0.00 10.00 2 |__revalidator113 07:37:57 AM 995 - 188569 5.00 5.00 0.00 10.00 2 |__revalidator116 07:37:57 AM 995 - 188570 5.00 6.00 0.00 11.00 2 |__revalidator117 07:37:57 AM 995 - 188571 5.00 5.00 0.00 10.00 2 |__revalidator114 07:37:57 AM 995 - 188572 5.00 6.00 0.00 11.00 2 |__revalidator115&lt;/pre&gt; &lt;h2 id="how-to-troubleshoot-find-that-is-really-an-fdb-wrapping-issue"&gt;Troubleshooting an FDB wrapping issue&lt;/h2&gt; &lt;p&gt;Let’s figure out if the high revalidator thread CPU usage is related to the FDB requesting a cleanup. This can be done by inspecting the coverage counters. The following shows all coverage counters (that have a value higher than zero) related to causes for the revalidator running:&lt;/p&gt; &lt;pre&gt;$ ovs-appctl coverage/show | grep -E "rev_|Event coverage" Event coverage, avg rate over last: 5 seconds, last minute, last hour, hash=e4a796fd: rev_reconfigure 0.0/sec 0.067/sec 0.0144/sec total: 299 rev_flow_table 0.0/sec 0.000/sec 0.0003/sec total: 2 rev_mac_learning 20.4/sec 18.167/sec 12.4039/sec total: 44660&lt;/pre&gt; &lt;p&gt;In the above output, you can see that &lt;code&gt;rev_mac_learning&lt;/code&gt; has triggered the revalidation process about 20 times per second. This is quite high. In theory, it could still happen due to the normal FDB aging process, although in that specific case the last minute/hour values should be lower.&lt;/p&gt; &lt;p&gt;Hower normal aging can be isolated by using the same coverage counters:&lt;/p&gt; &lt;pre&gt;$ ovs-appctl coverage/show | grep -E "mac_learning_|Event" Event coverage, avg rate over last: 5 seconds, last minute, last hour, hash=086fdd98: mac_learning_learned 1836.2/sec 1157.800/sec 1169.0800/sec total: 7752613 mac_learning_expired 0.0/sec 0.000/sec 1.1378/sec total: 4353&lt;/pre&gt; &lt;p&gt;As you can see, there are &lt;code&gt;mac_learning_learned&lt;/code&gt; and &lt;code&gt;mac_learning_expired&lt;/code&gt; counters. In the above output, you can see a lot of new MAC addresses have been learned: around 1,836 per second. For an FDB table with the size of 2K, this is extremely high and would indicate we are replacing FDB entries.&lt;/p&gt; &lt;p&gt;If you are running Open vSwitch v2.10 or newer, it has additional coverage counters:&lt;/p&gt; &lt;pre&gt;$ ovs-appctl coverage/show | grep -E "mac_learning_|Event" Event coverage, avg rate over last: 5 seconds, last minute, last hour, hash=0ddb1578: mac_learning_learned 0.0/sec 0.000/sec 10.6514/sec total: 38345 mac_learning_expired 0.0/sec 0.000/sec 2.2756/sec total: 8192 mac_learning_evicted 0.0/sec 0.000/sec 8.3758/sec total: 30153 mac_learning_moved 0.0/sec 0.000/sec 0.0000/sec total: 1&lt;/pre&gt; &lt;p&gt;Explanation of the above:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;mac_learning_learned&lt;/code&gt;: Shows the total number of learned MAC entries&lt;/li&gt; &lt;li&gt;&lt;code&gt;mac_learning_expired&lt;/code&gt;: Shows the total number of expired MAC entries&lt;/li&gt; &lt;li&gt;&lt;code&gt;mac_learning_evicted&lt;/code&gt;: Shows the total number of evicted MAC entries, that is, entries moved out due to the table being full&lt;/li&gt; &lt;li&gt;&lt;code&gt;mac_learning_moved&lt;/code&gt;: Shows the total number of &amp;#8220;port moved&amp;#8221; MAC entries, that is, entries where the MAC address moved to a different port&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now, how can you determine which bridge has an FDB wrapping issue? For v2.9 and earlier, it’s a manual process of dumping the FDB table a couple of times, using the command &lt;code&gt;ovs-appctl fdb/show&lt;/code&gt;, and comparing the entries.&lt;/p&gt; &lt;p&gt;For v2.10 and higher a new command was introduced, &lt;code&gt;ovs-appctl fdb/stats-show&lt;/code&gt;, which shows all the above statistics on a per-bridge basis:&lt;/p&gt; &lt;pre&gt;$ ovs-appctl fdb/stats-show ovs0 Statistics for bridge "ovs0": Current/maximum MAC entries in the table: 8192/8192 Total number of learned MAC entries : 52779 Total number of expired MAC entries : 8192 Total number of evicted MAC entries : 36395 Total number of port moved MAC entries : 1&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The statistics can be cleared with the command &lt;code&gt;ovs-appctl fdb/stats-clear&lt;/code&gt;, for example, to get a per-second rate:&lt;/p&gt; &lt;pre&gt;$ ovs-appctl fdb/stats-clear ovs0; sleep 1; ovs-appctl fdb/stats-show ovs0 statistics successfully cleared Statistics for bridge "ovs0": Current/maximum MAC entries in the table: 8192/8192 Total number of learned MAC entries : 1902 Total number of expired MAC entries : 0 Total number of evicted MAC entries : 1902 Total number of port moved MAC entries : 0&lt;/pre&gt; &lt;h2 id="fixing-the-fdb-table-size"&gt;Fixing the FDB table size&lt;/h2&gt; &lt;p&gt;With Open vSwitch, you can easily adjust the size of the FDB table, and it’s configurable per bridge. The command to do this is as follows:&lt;/p&gt; &lt;pre&gt;ovs-vsctl set bridge &amp;#60;bridge&amp;#62; other-config:mac-table-size=&amp;#60;size&amp;#62;&lt;/pre&gt; &lt;p&gt;When you change the configuration, take note of the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The number of FDB entries can be from 10 to 1,000,000.&lt;/li&gt; &lt;li&gt;The configuration is active immediately.&lt;/li&gt; &lt;li&gt;The current entries are not flushed from the table.&lt;/li&gt; &lt;li&gt;If a smaller number is configured than the number of entries currently in the table, the oldest entries are aged out. You can see this in the &lt;em&gt;expired MAC entries&lt;/em&gt; statistics.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Why not change the default to 1 million and stop worrying about this? Resource consumption: each entry in the table allocates memory. Although Open vSwitch allocates memory only when the entry is in use, changing the default to a too-high value could become a problem, for example, when someone does a &lt;a href="https://en.wikipedia.org/wiki/MAC_flooding"&gt;MAC flooding attack&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So what would be the correct size to configure? This is hard to tell and depends on your use case. As a rule of thumb, you should configure your table a bit larger than the average number of active MAC addresses on your bridge.&lt;/p&gt; &lt;h2 id="simple-reproducer"&gt;Simple script to see FDB wrapping effects&lt;/h2&gt; &lt;p&gt;If you would like to experiment with the counters, the following reproducer script from &lt;em&gt;Jiri Benc&lt;/em&gt;, which lets you reproduce the effects of FDB wrapping, will let you do this.&lt;/p&gt; &lt;p&gt;Create an Open vSwitch bridge:&lt;/p&gt; &lt;pre&gt;$ ovs-vsctl add-br ovs0 $ ip link set ovs0 up&lt;/pre&gt; &lt;p&gt;Create the reproducer script:&lt;/p&gt; &lt;pre&gt;$ cat &amp;#62; ~/reproducer.py &amp;#60;&amp;#60;EOF #!/usr/bin/python from scapy.all import * data = [(str("00" + str(RandMAC())[2:]), str(RandIP())) for i in range(int(sys.argv[1]))] s = conf.L2socket(iface="ovs0") while True: for mac, ip in data: p = Ether(src=mac, dst=mac)/IP(src=ip, dst=ip) s.send(p) EOF $ chmod +x ~/reproducer.py&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The reproducer Python script requires &lt;a href="https://scapy.readthedocs.io/en/latest/installation.html"&gt;Scapy&lt;/a&gt; to be installed.&lt;/p&gt; &lt;p&gt;Start the reproducer:&lt;/p&gt; &lt;pre&gt;$ ./reproducer.py 10000&lt;/pre&gt; &lt;p&gt;Now you can use the counter commands in the previous troubleshooting section to see the FDB table wrapping information and then set the size of the FDB appropriately.&lt;/p&gt; &lt;h2&gt;Additional Open vSwitch and Open Virtual Network resources&lt;/h2&gt; &lt;p&gt;Many of Red Hat’s products, such as Red Hat OpenStack Platform and Red Hat Virtualization, are now using Open Virtual Network (OVN) a sub-project of Open vSwitch. &lt;a href="https://developers.redhat.com/products/openshift/overview/"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; will be using OVN soon. Some other virtual networking articles on the Red Hat Developer blog:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/09/03/ovn-dynamic-ip-address-management/"&gt;Dynamic IP Address Management in Open Virtual Network (OVN): Part One&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/03/23/non-root-open-vswitch-rhel/"&gt;Non-root Open vSwitch in Red Hat Enterprise Linux&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/"&gt;Debugging memory issues with Open vSwitch DPDK&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/"&gt;Troubleshooting Open vSwitch DPDK PMD Thread Core Affinity&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/03/16/ovs-dpdk-hugepage-memory/"&gt;Open vSwitch-DPDK: How Much Hugepage Memory?&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;linkname=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F19%2Ftroubleshooting-fdb-table-wrapping-in-open-vswitch%2F&amp;#38;title=Troubleshooting%20FDB%20table%20wrapping%20in%20Open%20vSwitch" data-a2a-url="https://developers.redhat.com/blog/2018/09/19/troubleshooting-fdb-table-wrapping-in-open-vswitch/" data-a2a-title="Troubleshooting FDB table wrapping in Open vSwitch"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/19/troubleshooting-fdb-table-wrapping-in-open-vswitch/"&gt;Troubleshooting FDB table wrapping in Open vSwitch&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/4wxxeyKr8eA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;When most people deploy an Open vSwitch configuration for virtual networking using the NORMAL rule, that is, using L2 learning, they do not think about configuring the size of the Forwarding DataBase (FDB). When hardware-based switches are used, the FDB size is generally rather large and the large FDB size is a key selling point. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/19/troubleshooting-fdb-table-wrapping-in-open-vswitch/"&gt;Troubleshooting FDB table wrapping in Open vSwitch&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/09/19/troubleshooting-fdb-table-wrapping-in-open-vswitch/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">519187</post-id><dc:creator>Eelco Chaudron</dc:creator><dc:date>2018-09-19T11:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/09/19/troubleshooting-fdb-table-wrapping-in-open-vswitch/</feedburner:origLink></entry><entry><title>Build and Deploy Containerized Java Batch Applications on OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cebexgJ8joo/build-and-deploy-containerized-java-batch-applications-on-openshift" /><category term="feed_group_name_jberet" scheme="searchisko:content:tags" /><category term="feed_name_jberet" scheme="searchisko:content:tags" /><category term="jberet" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Cheng Fang</name></author><id>searchisko:content:id:jbossorg_blog-build_and_deploy_containerized_java_batch_applications_on_openshift</id><updated>2018-09-18T02:47:33Z</updated><published>2018-09-18T02:47:33Z</published><content type="html">&lt;!-- [DocumentBodyStart:86a98098-d31e-4faa-b426-9403a4a67c60] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;h2&gt;Introduction&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;When migrating Java batch applications to cloud platforms such as OpenShift, there are different approaches how to build and containerize traditional applications.&amp;#160; Recall that JSR-352-based Java batch applications can be developed and run in either Java SE or Java EE (now &lt;a class="jive-link-external-small" href="https://jakarta.ee/" rel="nofollow"&gt;Jakarta EE&lt;/a&gt;) environment.&amp;#160; So if your existing Java batch applications are Java EE web or enterprise applications deployed to application servers like WildFly, then you would build the new cloud batch applications based on OpenShift WildFly image streams and run it WildFly runtime on OpenShift.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If you've chosen to develop and run your existing Java batch applications as light-weight standalone Java SE applications, it's also easy to migrate to OpenShift using openjdk image steams and runtime.&amp;#160; This is what we will be exploring in this blog post to help JBeret users better understand the concepts and steps it takes to modernize batch applications.&amp;#160; OpenShift provides a Java S2I (source-to-image) builder process that handles everything from building application source code, injecting application to the base image, publishing to OpenShift image registry, and readying the application for execution.&amp;#160; A JBeret sample batch application, &lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-simple" rel="nofollow"&gt;jberet-simple&lt;/a&gt;, will be used to illustrate each step.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Set up, Build and Run Sample Batch Application the Traditional Way&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;First, let's see how to build and run the sample application the traditionaly way locally, and familiarize ourselves with the application structure and batch job.&amp;#160; jberet-simple is a simple standalone Java SE batch processing application and contains a single batch job as defined in simple.xml.&amp;#160; This batch job contains a single chunk-type step that reads a list of numbers by chunks and prints them to the console. The 2 batch artifacts used in this application are:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support/blob/master/src/main/java/org/jberet/support/io/ArrayItemReader.java" rel="nofollow"&gt;arrayItemReader&lt;/a&gt;: implemented in &lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support" rel="nofollow"&gt;jberet-support&lt;/a&gt;, reads a list of objects configured in job xml&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support/blob/master/src/main/java/org/jberet/support/io/MockItemWriter.java" rel="nofollow"&gt;mockItemWriter&lt;/a&gt;: implemented in &lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support" rel="nofollow"&gt;jberet-support&lt;/a&gt;, writes the output to the console or other destinations&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;For complete batch job definition, see the JSL file &lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-simple/blob/master/src/main/resources/META-INF/batch-jobs/simple.xml" rel="nofollow"&gt;simple.xml&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To git-clone the sample application from github:&lt;/p&gt;&lt;!--[CodeBlockStart:119570e8-a803-430d-979a-0fe9044859a9][excluded]--&gt;&lt;pre class="plain" name="code"&gt;git clone https://github.com/jberet/jberet-simple.git&lt;/pre&gt;&lt;!--[CodeBlockEnd:119570e8-a803-430d-979a-0fe9044859a9]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To build the sample application with Maven, including running the integration test:&lt;/p&gt;&lt;!--[CodeBlockStart:3f680f8b-18ff-4d4d-9533-3b4501042330][excluded]--&gt;&lt;pre class="plain" name="code"&gt;mvn clean install&lt;/pre&gt;&lt;!--[CodeBlockEnd:3f680f8b-18ff-4d4d-9533-3b4501042330]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To run the integration test that starts the batch job:&lt;/p&gt;&lt;!--[CodeBlockStart:302f6ccf-08f6-4423-b04c-b9208522b6d7][excluded]--&gt;&lt;pre class="plain" name="code"&gt;mvn integration-test&lt;/pre&gt;&lt;!--[CodeBlockEnd:302f6ccf-08f6-4423-b04c-b9208522b6d7]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To run application main class with maven exec plugin, execute any of the following mvn commands:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:a06ade4c-af8a-4d5e-b27b-4e4d176a485f][excluded]--&gt;&lt;pre class="plain" name="code"&gt;# run with the default configuration in pom.xml mvn exec:java # run with job xml mvn exec:java -Dexec.arguments="simplxe.xml" # run with job xml and job parameters mvn exec:java -Dexec.arguments="simple.xml jobParam1=x jobParam2=y jobParam3=z"&lt;/pre&gt;&lt;!--[CodeBlockEnd:a06ade4c-af8a-4d5e-b27b-4e4d176a485f]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To build&amp;#160; the application as an executable uber jar (fat jar) and run it directly with java -jar command:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:e6545a74-8247-4a62-90d2-85b9fa5b6d25][excluded]--&gt;&lt;pre class="plain" name="code"&gt;mvn clean install -Popenshift java -jar target/jberet-simple.jar simple.xml jobParam1=x jobParam2=y&lt;/pre&gt;&lt;!--[CodeBlockEnd:e6545a74-8247-4a62-90d2-85b9fa5b6d25]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Note that in the above command, a maven profile named openshift is used.&amp;#160; This profile tells maven to build the uber jar to include everything needed to run the application.&amp;#160; When openshift profile is present, it will be picked up by OpenShift S2I builder process instead of the default profile.&amp;#160; Of course, this profie can also be invoked manually as we just did above.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Build Application Images and Deploy to OpenShift&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Next, let's delve into how to run jberet-simple application on OpenShift.&amp;#160; Since this is a standalone Java SE application, OpenShift will need to enlist a Java SE runtime, and here we choose to use openjdk18.&amp;#160; All the operations we will be performing can be done via either OpenShift command line tool (oc), or OpenShift Web Console.&amp;#160; For the sake of brevity, we will use oc commands.&amp;#160; For introduction to various features in OpenShift, you may want to check out &lt;a class="jive-link-external-small" href="https://learn.openshift.com/" rel="nofollow"&gt;OpenShift interactive tutorials&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We assume you already have an OpenShift account, and to log in:&lt;/p&gt;&lt;!--[CodeBlockStart:395e27c6-f342-4bfb-ae2e-53868fe5dedb][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc login https:xxx.openshift.com --token=xxx&lt;/pre&gt;&lt;!--[CodeBlockEnd:395e27c6-f342-4bfb-ae2e-53868fe5dedb]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To create a new project, if there is no existing projects:&lt;/p&gt;&lt;!--[CodeBlockStart:0f59bd28-0676-4fdb-88c8-102e694e9ecd][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc new-project &lt;/pre&gt;&lt;!--[CodeBlockEnd:0f59bd28-0676-4fdb-88c8-102e694e9ecd]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We wil use openjdk18-openshift image stream. Check if it is available in the current project:&lt;/p&gt;&lt;!--[CodeBlockStart:58f3e12e-4f76-4ac5-8ca7-4d33721706ab][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc get is&lt;/pre&gt;&lt;!--[CodeBlockEnd:58f3e12e-4f76-4ac5-8ca7-4d33721706ab]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If openjdk18-openshift is not present, import it:&lt;/p&gt;&lt;!--[CodeBlockStart:93d0b6e6-2695-4a2f-a6e4-6ee01372c4d7][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc import-image my-redhat-openjdk-18/openjdk18-openshift --from=registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift --confirm&lt;/pre&gt;&lt;!--[CodeBlockEnd:93d0b6e6-2695-4a2f-a6e4-6ee01372c4d7]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;to create a new application (with default name):&lt;/p&gt;&lt;!--[CodeBlockStart:0bc07f39-06be-493f-b4d5-bd49988df3a4][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc new-app openjdk18-openshift~https://github.com/jberet/jberet-simple.git&lt;/pre&gt;&lt;!--[CodeBlockEnd:0bc07f39-06be-493f-b4d5-bd49988df3a4]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Or to create a new application with custom name, if the default name doesn't fit:&lt;/p&gt;&lt;!--[CodeBlockStart:996c936a-7849-460e-b3e1-8412776a1261][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc new-app openjdk18-openshift~https://github.com/jberet/jberet-simple.git --name=hello-batch&lt;/pre&gt;&lt;!--[CodeBlockEnd:996c936a-7849-460e-b3e1-8412776a1261]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The above new-app command takes a while to complete.&amp;#160; To check its status:&lt;/p&gt;&lt;!--[CodeBlockStart:5f904305-6bfb-411f-bca4-39d74223898f][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc status&lt;/pre&gt;&lt;!--[CodeBlockEnd:5f904305-6bfb-411f-bca4-39d74223898f]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To list pods, and get logs for the pod associated with the application (replace jberet-simple-1-kpvqn with your pod name):&lt;/p&gt;&lt;!--[CodeBlockStart:dd40485f-d536-405b-94c8-6f5614561306][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc get pods oc logs jberet-simple-1-kpvqn&lt;/pre&gt;&lt;!--[CodeBlockEnd:dd40485f-d536-405b-94c8-6f5614561306]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;table&gt;&lt;tbody&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;From the above log output, you can see that the application has been successfully built, deployed to OpenShift online, and batch job executed.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Launch a Job Execution from OpenShift Command Line&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;By now we've successfully built, deployed to OpenShift and started the batch job execution.&amp;#160; You want want to run it again later as needed, and this can be easily done with OpenShift command line with oc client tool and Kubernetes job api.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;First, create a yaml file to describe how OpenShift should run the batch application.&amp;#160; For example, I created the following file, simple.yaml, to launch the batch application (replace container image value to the appropriate one in your OpenShift environment):&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:270a8004-46da-4f59-9467-35fa8b53d688][excluded]--&gt;&lt;pre class="javascript" name="code"&gt;apiVersion: batch/v1 kind: Job metadata: &amp;#160; name: simple spec: &amp;#160; parallelism: 1 &amp;#160; completions: 1 &amp;#160; template: &amp;#160;&amp;#160;&amp;#160; metadata: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; name: simple &amp;#160;&amp;#160;&amp;#160; spec: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; containers: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; - name: jberet-simple &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; image: docker-registry.default.svc:5000/pr/jberet-simple &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; command: ["java",&amp;#160; "-jar", "/deployments/jberet-simple.jar", "simple.xml", "jobParam1=x", "jobParam2=y"] &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; restartPolicy: OnFailure&lt;/pre&gt;&lt;!--[CodeBlockEnd:270a8004-46da-4f59-9467-35fa8b53d688]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Then, run the following command to tell OpenShift to launch the job execution:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:8a2a7b47-55b7-4a15-bf7f-24a75dc01ae8][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc create -f simple.yaml job.batch "simple" created&lt;/pre&gt;&lt;!--[CodeBlockEnd:8a2a7b47-55b7-4a15-bf7f-24a75dc01ae8]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To list Kubernetes jobs:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:cabc86fa-5a50-437a-b6f6-fc99591a08e6][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc get jobs NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; DESIRED&amp;#160;&amp;#160; SUCCESSFUL&amp;#160;&amp;#160; AGE simple&amp;#160;&amp;#160;&amp;#160; 1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 12m&lt;/pre&gt;&lt;!--[CodeBlockEnd:cabc86fa-5a50-437a-b6f6-fc99591a08e6]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To list pods, including the one responsible for running the above simple batch application:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:97e89d04-d760-410a-9443-d11eb1cc19c7][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc get pods NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; READY&amp;#160;&amp;#160;&amp;#160;&amp;#160; STATUS&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; RESTARTS&amp;#160;&amp;#160; AGE jberet-simple-5-build&amp;#160;&amp;#160; 0/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Completed&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 11h jberet-simple-6-build&amp;#160;&amp;#160; 0/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Completed&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 8h jberet-simple-6-wwjm7&amp;#160;&amp;#160; 0/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; CrashLoopBackOff&amp;#160;&amp;#160; 105&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 8h postgresql-5-sbfm5&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Running&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1d simple-mpq8h&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Completed&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 8h&lt;/pre&gt;&lt;!--[CodeBlockEnd:97e89d04-d760-410a-9443-d11eb1cc19c7]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To view logs from the above simple batch job execution, passing the appropriate pod name:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:89d65a6e-80f7-48d1-928e-6b82b6945651][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc logs simple-mpq8h&lt;/pre&gt;&lt;!--[CodeBlockEnd:89d65a6e-80f7-48d1-928e-6b82b6945651]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To delete the job created in above step:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:9280ec68-16d4-46e2-ad5d-b331fa1ddafa][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc delete job simple job.batch "simple" deleted&lt;/pre&gt;&lt;!--[CodeBlockEnd:9280ec68-16d4-46e2-ad5d-b331fa1ddafa]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Schedule Repeating Job Executions with Kubernetes Cron Jobs from OpenShift Command Line&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;You may be wondering if it's possible to schedule periodic batch job executions from OpenShift command line.&amp;#160; The answer is yes, and this is supported with Kubernetes cron job api, similar to launching one-time job execution as demonstrated above.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;First, create a yaml file to define the Kubernetes crob job spec.&amp;#160; In the following example, simple-cron.yaml, the cron expression `*/1 * * * *` specifies running the batch job every minute.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:983fea3e-f445-4035-8c0c-2c1ec5a70d16][excluded]--&gt;&lt;pre class="javascript" name="code"&gt;apiVersion: batch/v1beta1 kind: CronJob metadata: &amp;#160; name: simple-cron spec: &amp;#160; successfulJobsHistoryLimit: 3 &amp;#160; failedJobsHistoryLimit: 1 &amp;#160; schedule: "*/1 * * * *" &amp;#160; jobTemplate: &amp;#160;&amp;#160;&amp;#160; spec: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; template: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; spec: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; containers: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; - name: simple-cron &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; image: docker-registry.default.svc:5000/pr/jberet-simple &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; command: ["java",&amp;#160; "-jar", "/deployments/jberet-simple.jar", "simple.xml", "jobParam1=x", "jobParam2=y"] &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; restartPolicy: OnFailure&lt;/pre&gt;&lt;!--[CodeBlockEnd:983fea3e-f445-4035-8c0c-2c1ec5a70d16]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Then, run the following commands to tell OpenShift to schedule the job executions:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:b3845644-6648-4796-8f0a-2345c302447a][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc create -f simple-cron.yaml cronjob.batch "simple-cron" created&lt;/pre&gt;&lt;!--[CodeBlockEnd:b3845644-6648-4796-8f0a-2345c302447a]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To list all cron jobs:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:780ad26a-cd19-4e4f-936d-67484600d934][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc get cronjobs NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; SCHEDULE&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; SUSPEND&amp;#160;&amp;#160; ACTIVE&amp;#160;&amp;#160;&amp;#160; LAST SCHEDULE&amp;#160;&amp;#160; AGE simple-cron&amp;#160;&amp;#160; */1 * * * *&amp;#160;&amp;#160; False&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 7s&lt;/pre&gt;&lt;!--[CodeBlockEnd:780ad26a-cd19-4e4f-936d-67484600d934]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To get status of a specific cron job:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:452f3e24-1bd9-4fdf-afea-4aa5b54380b8][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc get cronjob simple-cron NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; SCHEDULE&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; SUSPEND&amp;#160;&amp;#160; ACTIVE&amp;#160;&amp;#160;&amp;#160; LAST SCHEDULE&amp;#160;&amp;#160; AGE simple-cron&amp;#160;&amp;#160; */1 * * * *&amp;#160;&amp;#160; False&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 24s&lt;/pre&gt;&lt;!--[CodeBlockEnd:452f3e24-1bd9-4fdf-afea-4aa5b54380b8]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To get continuous status of a specific cron job with --watch option:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:aa2cd8ca-caf1-4012-92e2-ae588140b5ff][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc get cronjob simple-cron --watch NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; SCHEDULE&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; SUSPEND&amp;#160;&amp;#160; ACTIVE&amp;#160;&amp;#160;&amp;#160; LAST SCHEDULE&amp;#160;&amp;#160; AGE simple-cron&amp;#160;&amp;#160; */1 * * * *&amp;#160;&amp;#160; False&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 33s simple-cron&amp;#160;&amp;#160; */1 * * * *&amp;#160;&amp;#160; False&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 7s&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 46s simple-cron&amp;#160;&amp;#160; */1 * * * *&amp;#160;&amp;#160; False&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 37s&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1m&lt;/pre&gt;&lt;!--[CodeBlockEnd:aa2cd8ca-caf1-4012-92e2-ae588140b5ff]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To get all pods, including the pods responsible for running scheduled job executions:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:903df839-b989-4fe1-866f-9b472d24156a][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc get pods NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; READY&amp;#160;&amp;#160;&amp;#160;&amp;#160; STATUS&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; RESTARTS&amp;#160;&amp;#160; AGE postgresql-5-sbfm5&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Running&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 27d simple-cron-1536609780-fmrhf&amp;#160;&amp;#160; 0/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; ContainerCreating&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 1s simple-mpq8h&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0/1&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Completed&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; 26d&lt;/pre&gt;&lt;!--[CodeBlockEnd:903df839-b989-4fe1-866f-9b472d24156a]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To view logs of one of the scheduled job executions, passing the appropriate pod name:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:c33aabc5-0e6f-481b-bb89-f6c94c156b48][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc logs simple-cron-1536609780-fmrhf&lt;/pre&gt;&lt;!--[CodeBlockEnd:c33aabc5-0e6f-481b-bb89-f6c94c156b48]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To delete the cron job created above:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:5ed1fc62-7392-44a5-b40f-bf8244af9b75][excluded]--&gt;&lt;pre class="plain" name="code"&gt;$ oc delete cronjob simple-cron cronjob.batch "simple-cron" deleted&lt;/pre&gt;&lt;!--[CodeBlockEnd:5ed1fc62-7392-44a5-b40f-bf8244af9b75]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Summary&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In this blog post, we demonstrated with a sample Java batch application how to run it locally, build and deploy containerized application to OpenShift, launch batch job execution from OpenShift command line, and schedule cron jobs of periodic batch job executions.&amp;#160; This post just touches some of the basics of running batch jobs in OpenShift platform, and there are many options for concurrency, scalability and restartability that are worth exploring further.&amp;#160; I hope you find it useful in your batch applicaton development, and feedback and comments are always welcome to help us improve project JBeret.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:86a98098-d31e-4faa-b426-9403a4a67c60] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cebexgJ8joo" height="1" width="1" alt=""/&gt;</content><summary>Introduction   When migrating Java batch applications to cloud platforms such as OpenShift, there are different approaches how to build and containerize traditional applications.  Recall that JSR-352-based Java batch applications can be developed and run in either Java SE or Java EE (now Jakarta EE) environment.  So if your existing Java batch applications are Java EE web or enterprise application...</summary><dc:creator>Cheng Fang</dc:creator><dc:date>2018-09-18T02:47:33Z</dc:date><feedburner:origLink>https://developer.jboss.org/community/jberet/blog/2018/09/17/build-and-deploy-containerized-java-batch-applications-on-openshift</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 18/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fRx-hyrHvbU/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_18_2018</id><updated>2018-09-19T05:14:14Z</updated><published>2018-09-18T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Starting with JPA and Hibernate is fairly easy. However, getting the best out of the underlying database system, JDBC driver or JPA implementation is what many developers find challenging. &lt;a href="https://vladmihalcea.com/hibernate-performance-tuning-tips/"&gt;These Hibernate performance tuning tips&lt;/a&gt; are going to help you speed uo your data access layer, as well as getting a better understanding of how Hibernate works behind the scenes.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Eugen Paraschiv wrote a very good article which teaches you &lt;a href="https://stackify.com/java-performance/"&gt;how to improve the performance of a Java application&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Marko Bekhta wrote an article about &lt;a href="https://that-java-guy.blogspot.com/2018/09/bean-validation-validation-based-on.html"&gt;validating multiple properties with Bean Validation&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When using JPA and Hibernate, it’s not uncommon to want to clone or duplicate a given entity. &lt;a href="https://vladmihalcea.com/clone-duplicate-entity-jpa-hibernate/"&gt;This article&lt;/a&gt; shows you how to use the copy constructor to clone an entity so that you control the associations being cloned.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you want to know how to leverage the full-text search capabilities of SAP HANA using Hibernate, check out &lt;a href="https://www.sap.com/developer/tutorials/hxe-gcp-hibernate-text-search.html"&gt;this article&lt;/a&gt; written by Jonathan Bregler.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://www.baeldung.com/database-auditing-jpa"&gt;This article&lt;/a&gt; shows you three ways you can implement an audit log when using JPA and Hibernate:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;custom JPA callbacks,&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Hibernate Envers or&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Spring Data Audit capabilities&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In &lt;a href="https://www.baeldung.com/hibernate-query-to-custom-class"&gt;this article&lt;/a&gt;, you will see how to map an entity query to a custom DTO class using the JPA constructor result or the Hibernate-specific &lt;code&gt;ResultTransformer&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="time-to-upgrade"&gt;&lt;a class="anchor" href="#time-to-upgrade"&gt;&lt;/a&gt;Time to upgrade&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Hibernate Search has released &lt;a href="http://in.relation.to/2018/09/13/hibernate-search-5-10-4-Final-5-9-3-Final-5-6-6-Final/"&gt;three versions (5.10.4, 5.9.3, 5.6.6)&lt;/a&gt;. If you’re using Hibernate Search, you might want to upgrade to the latest version of your branch and benefit from all the enhancements being added to the project.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JHipster &lt;a href="https://www.jhipster.tech/2018/09/03/jhipster-release-5.3.0.html"&gt;5.3.0 has been released&lt;/a&gt;, and it now supports the &lt;a href="https://github.com/jhipster/generator-jhipster/issues/8146"&gt;&lt;code&gt;hibernate.connection.provider_disables_autocommit&lt;/code&gt;&lt;/a&gt; Hibernate configuration property.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-query-cache-invalidation-after-persisting-entity/1334"&gt;Hibernate Query Cache invalidation after persisting entity&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-to-select-multiple-many-to-many-associations-efficiently-using-jpql/1344"&gt;How to select multiple many-to-many associations efficiently using JPQL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-to-integrate-a-second-database-with-jpa-and-hibernate/1342"&gt;How to integrate a second database with JPA and Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/11625096/cloning-jpa-entity"&gt;Cloning a JPA entity&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52200422/how-to-run-a-hibernate-nativequery-in-a-type-safe-manner-returning-an-object/52251791#52251791"&gt;How to run a Hibernate NativeQuery in a type-safe manner instead of returning an &lt;code&gt;Object[&lt;/code&gt;&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/11043712/what-is-the-difference-between-non-repeatable-read-and-phantom-read/51123574#51123574"&gt;What is the difference between Non-Repeatable Read and Phantom Read?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52207233/hibernate-saves-retrieves-date-minus-day-if-application-uses-another-timezone-th/52211300#52211300"&gt;Hibernate saves/retrieves date minus day if the application uses another timezone than MySQL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/337072/what-are-the-first-and-second-level-caches-in-hibernate/51306851#51306851"&gt;What are the First and Second Level caches in Hibernate?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/does-hibernate-provide-a-way-to-invalidate-l2-cache/1405"&gt;Does Hibernate provide a way to invalidate L2 cache?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/persisting-a-custom-uuid-class-as-a-varchar/1404"&gt;Persisting a custom UUID class as a VARCHAR&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-add-relationship-between-two-unrelated-entities-not-related-by-foreign-key/1369"&gt;Hibernate add relationship between two unrelated entities (not related by foreign key)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/logging-query-elides-where-clause/1392/2"&gt;Logging query elides where clause&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/oracle-ht-tables-are-created-for-inheritence-type-table-per-class/1388/7"&gt;Oracle: HT_ tables are created for inheritance type table-per-class&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-to-clone-an-entity-with-jpa-and-hibernate/1149/3"&gt;How to clone an entity with JPA and Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/39382213/can-you-give-me-some-tips-for-hibernate-performance-tuning"&gt;Hibernate performance tuning tips&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fRx-hyrHvbU" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Articles Starting with JPA and Hibernate is fairly easy. However, getting the best out of the underlying database system, JDBC driver or JPA implementation is what many developers find challenging. These Hibernate performance tuning tips are goin...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-09-18T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/09/18/hibernate-community-newsletter-2018-18/</feedburner:origLink></entry><entry><title>Configuring the MongoDB WiredTiger memory cache for RHMAP</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/8hV-sAVy1_o/" /><category term="Red Hat Mobile Application Platform" /><category term="Red Hat OpenShift Container Platform" /><category term="FeedHenry" /><category term="memory cache" /><category term="mobile" /><category term="MongoDB" /><category term="performance" /><category term="Performance Improvements" /><category term="Red Hat OpenShift" /><category term="RHMAP" /><category term="WiredTiger" /><author><name>Camila Macedo</name></author><id>https://developers.redhat.com/blog/?p=518297</id><updated>2018-09-17T11:00:34Z</updated><published>2018-09-17T11:00:34Z</published><content type="html">&lt;p&gt;This article describes how to configure MongoDB&amp;#8217;s WiredTiger memory cache in &lt;a href="https://developers.redhat.com/products/mobileplatform/overview/"&gt;Red Hat Mobile Application Platform&lt;/a&gt; (RHMAP) to prevent high-usage memory issues and Nagios alerts. If the WiredTiger cache consumes all the memory available for a container, memory issues and Nagios alerts will occur.&lt;/p&gt; &lt;p&gt;The WiredTiger storage engine is the default storage engine starting in MongoDB version 3.2. It uses MultiVersion Concurrency Control (&lt;a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control"&gt;MVCC&lt;/a&gt;) architecture for write operations in order to allow multiple different modifications to the same document at the same time.&lt;/p&gt; &lt;p&gt;WiredTiger also caches data and creates checkpoints to give you the ability to recover anytime it’s necessary. For example, if a MongoDB image deployed in a container fails, it is useful to recover the data that was not persisted. Additionally, WiredTiger can recover un-checkpointed data with its journal files. See the &lt;a href="https://docs.mongodb.com/manual/core/wiredtiger/#journal"&gt;journal documentation&lt;/a&gt; and &lt;a href="https://docs.mongodb.com/manual/core/wiredtiger/#storage-wiredtiger-checkpoints"&gt;snapshots and checkpoint documentation&lt;/a&gt; for more information.&lt;/p&gt; &lt;p&gt;&lt;span id="more-518297"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Configuring memory usage&lt;/h2&gt; &lt;p&gt;To prevent memory issues and Nagios alerts, the property &lt;code&gt;storage.wiredTiger.engineConfig.cacheSizeGB&lt;/code&gt; should be set to a value less than the amount of RAM available in the container. Another option to achieve the same result is through the &lt;code&gt;–wiredTigerCacheSizeGB&lt;/code&gt; parameter.&lt;/p&gt; &lt;p&gt;In version 3.2 of MongoDB, the default configuration is to use 1GB of memory or 60% of the available amount of memory when the available amount is larger than one 1GB. This usage percentage was replaced by 50% in version 3.4 of MongoDB. For more details, see the &lt;a href="https://docs.mongodb.com/manual/reference/configuration-options/#storage.wiredTiger.engineConfig.cacheSizeGB"&gt;storage.wiredTiger.engineConfig.cacheSizeGB API documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Due to a bug in MongoDB 3.2, a workaround is required to accept values lower than 1Gi. The property &lt;code&gt;configString: cache_size=&amp;#60;cache-size&amp;#62;&lt;/code&gt; needs to be set in the MongoDB configuration. The following is an example of setting the property to 600MB:&lt;/p&gt; &lt;pre&gt;# storage options - How and where to store data storage: # Directory for datafiles (defaults to /data/db/) dbPath: ${MONGODB_DATADIR} wiredTiger: engineConfig: configString: cache_size=600M&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The bug &lt;em&gt;&amp;#8220;WiredTiger cache size is only configurable in whole gigabytes&amp;#8221;&lt;/em&gt; can be viewed &lt;a href="https://jira.mongodb.org/browse/SERVER-22274"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Avoiding high-usage memory alerts and issues related to MongoDB in RHMAP&lt;/h2&gt; &lt;p&gt;In version 4.6.5 or above of RHMAP, the WiredTiger memory cache will be already configured to use 60%/600MB of the default amount of available memory, which is 1GB in the newer RHMAP MongoDB image released. To check this image, see its catalog &lt;a href="https://access.redhat.com/containers/#/registry.access.redhat.com/rhmap46/mongodb"&gt;here&lt;/a&gt;. However, in the previous image, memory issues and high-usage memory alerts may be triggered in Nagios because the cache size configuration was not set.&lt;/p&gt; &lt;p&gt;It is recommended that the latest version of the product be used in order to achieve the best user experience and avoid technical debts. If this is not possible, then it is recommended to update all MongoDB instances&amp;#8217; configuration to include a proper value for the WiredTiger cache size in both projects: Core and MBaaS.&lt;/p&gt; &lt;p&gt;The following the steps are examples suggested by Shannon Poole, an RHMAP senior software engineer, to perform this configuration manually.&lt;/p&gt; &lt;p&gt;1. Create a &lt;a href="https://docs.openshift.com/container-platform/3.9/dev_guide/configmaps.html"&gt;ConfigMap&lt;/a&gt;, as shown in the following example:&lt;/p&gt; &lt;pre&gt;kind: ConfigMap apiVersion: v1 metadata: name: wired-tiger-config namespace: rhmap-3-node-mbaas data: mongod.conf: | ## ## For list of options visit: ## https://docs.mongodb.org/manual/reference/configuration-options/ ## # systemLog options - How to do logging systemLog: # Runs the mongod in a quiet mode that attempts to limit the # amount of output quiet: true # net options - Network interfaces settings net: # Specify port number (27017 by default) port: 27017 # storage options - How and where to store data storage: # Directory for datafiles (defaults to /data/db/) dbPath: /var/lib/mongodb/data wiredTiger: engineConfig: configString: cache_size=400M # replication options - Configures replication replication: # Specifies a maximum size in megabytes for the replication # operation log (i.e. the oplog, # 5% of disk space by default) oplogSizeMB: 64 &lt;/pre&gt; &lt;p&gt;2. Add the &lt;a href="https://docs.openshift.com/container-platform/3.9/dev_guide/configmaps.html"&gt;ConfigMap&lt;/a&gt; to the &lt;a href="https://docs.openshift.com/container-platform/3.9/dev_guide/deployments/basic_deployment_operations.html"&gt;deployment configuration (dc)&lt;/a&gt; of the MongoDB pod in order to mount it in the right place (&lt;code&gt;/etc/mongod.conf&lt;/code&gt;). To edit the deployment configuration, use the following command or the Red hat OpenShift console.&lt;/p&gt; &lt;pre&gt;$ oc edit dc/&amp;#60;deployment_config&amp;#62;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note: &lt;/strong&gt;See the &lt;a href="https://docs.openshift.com/container-platform/3.9/dev_guide/configmaps.html#configmaps-use-case-consuming-in-volumes"&gt;Consuming in Volumes&lt;/a&gt; section of the Red Hat OpenShift documentation for further information.&lt;/p&gt; &lt;p&gt;3. Update the MongoDB replica set container specification, as shown in the following example:&lt;/p&gt; &lt;pre&gt;containers: - volumeMounts: - name: wired-tiger-config mountPath: /etc/mongod.conf subPath: mongod.conf volumes: - name: wired-tiger-config configMap: name: wired-tiger-config&lt;/pre&gt; &lt;p&gt;4. Check the pod logs to verify the changes. See if the custom cache size will be there after MongoDB is redeployed. This customization will be described in the logs when MongoDB initializes, as shown in the following example:&lt;/p&gt; &lt;pre&gt;=&amp;#62; [Mon Aug 20 13:42:22] wiredTiger cacheSizeGB set to 1 =&amp;#62; [Mon Aug 20 13:42:22] Waiting for local MongoDB to accept connections … 2018-08-20T13:42:22.837+0000 I STORAGE [main] Engine custom option: cache_size=600M&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;If the memory amount allocated for the MongoDB instances will be changed, then it is recommended that you review the configuration and set an adequate value for the WiredTiger cache. There&amp;#8217;s no need to perform this configuration when the memory resource is bigger than 1GB, since the default set up is 60% of the total available in this situation. However, if a change is done in order to allocate 1GB or less, the recommendation is to customize this value, as explained in this post.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;linkname=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F09%2F17%2Fconfiguring-the-mongodb-wiredtiger-memory-cache-for-rhmap%2F&amp;#38;title=Configuring%20the%20MongoDB%20WiredTiger%20memory%20cache%20for%20RHMAP" data-a2a-url="https://developers.redhat.com/blog/2018/09/17/configuring-the-mongodb-wiredtiger-memory-cache-for-rhmap/" data-a2a-title="Configuring the MongoDB WiredTiger memory cache for RHMAP"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/17/configuring-the-mongodb-wiredtiger-memory-cache-for-rhmap/"&gt;Configuring the MongoDB WiredTiger memory cache for RHMAP&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/8hV-sAVy1_o" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article describes how to configure MongoDB&amp;#8217;s WiredTiger memory cache in Red Hat Mobile Application Platform (RHMAP) to prevent high-usage memory issues and Nagios alerts. If the WiredTiger cache consumes all the memory available for a container, memory issues and Nagios alerts will occur. The WiredTiger storage engine is the default storage engine starting in [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/09/17/configuring-the-mongodb-wiredtiger-memory-cache-for-rhmap/"&gt;Configuring the MongoDB WiredTiger memory cache for RHMAP&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/09/17/configuring-the-mongodb-wiredtiger-memory-cache-for-rhmap/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">518297</post-id><dc:creator>Camila Macedo</dc:creator><dc:date>2018-09-17T11:00:34Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/09/17/configuring-the-mongodb-wiredtiger-memory-cache-for-rhmap/</feedburner:origLink></entry><entry><title>Infinispan 9.4.0.CR3, 9.3.3 and codename vote</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/U_cNwBXdRxg/infinispan-940cr3-933-and-codename-vote.html" /><category term="9.3" scheme="searchisko:content:tags" /><category term="9.4" scheme="searchisko:content:tags" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><category term="release candidate" scheme="searchisko:content:tags" /><author><name>Tristan Tarrant</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_9_4_0_cr3_9_3_3_and_codename_vote</id><updated>2018-09-17T07:15:23Z</updated><published>2018-09-17T07:15:00Z</published><content type="html">Hi Infinispan Community,&lt;br /&gt;&lt;br /&gt;our original plan was to release 9.4 Final today, but we have decided to delay the release by an extra sprint (3 weeks).&lt;br /&gt;So today we are announcing 9.4.0.CR3 instead, which comes with the following fixes:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Segmented off-heap data container&lt;/li&gt;&lt;li&gt;Performance improvements for Near Caches&lt;/li&gt;&lt;li&gt;Hot Rod client-side statistics&lt;/li&gt;&lt;li&gt;Removal of the old compatibility mode in favor of the new transcoding capabilities is now complete&lt;/li&gt;&lt;li&gt;Server rebased on top of WildFly 14&lt;/li&gt;&lt;li&gt;Lots of code cleanups, especially around query&lt;/li&gt;&lt;li&gt;Bug fixes&lt;/li&gt;&lt;/ul&gt;For those of you on our stable branch, we also released a 9.3.3 with some bug fixes. &lt;br /&gt;&lt;ul&gt;&lt;/ul&gt;Please &lt;a href="http://infinispan.org/download/" target="_blank"&gt;download&lt;/a&gt;, &lt;a href="https://issues.jboss.org/projects/ISPN" target="_blank"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/" target="_blank"&gt;chat with us&lt;/a&gt;, ask questions on the &lt;a href="https://developer.jboss.org/en/infinispan/content" target="_blank"&gt;forum&lt;/a&gt; or on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest" target="_blank"&gt;StackOverflow&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;As this release is yet unnamed, please make sure you vote for the name:&lt;br /&gt;&lt;br /&gt;&lt;iframe frameborder="0" height="962" marginheight="0" marginwidth="0" src="https://docs.google.com/forms/d/e/1FAIpQLSflMswdzxG_q2cZWnQunW5D6-rFnbxvrg8ZTC5IsElYeAdgNw/viewform?embedded=true" width="640"&gt;Loading...&lt;/iframe&gt;&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/v3K4aVxD-bk" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/U_cNwBXdRxg" height="1" width="1" alt=""/&gt;</content><summary>Hi Infinispan Community, our original plan was to release 9.4 Final today, but we have decided to delay the release by an extra sprint (3 weeks). So today we are announcing 9.4.0.CR3 instead, which comes with the following fixes: Segmented off-heap data container Performance improvements for Near Caches Hot Rod client-side statistics Removal of the old compatibility mode in favor of the new transc...</summary><dc:creator>Tristan Tarrant</dc:creator><dc:date>2018-09-17T07:15:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/v3K4aVxD-bk/infinispan-940cr3-933-and-codename-vote.html</feedburner:origLink></entry><entry><title>Unpublish a npm package</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Q1Rl7OTT6xo/unpublish-npm-package.html" /><category term="feed_group_name_aerogear" scheme="searchisko:content:tags" /><category term="feed_name_corinnekrych" scheme="searchisko:content:tags" /><author><name>Corinne Krych</name></author><id>searchisko:content:id:jbossorg_blog-unpublish_a_npm_package</id><updated>2018-09-13T13:07:00Z</updated><published>2018-09-13T13:07:00Z</published><content type="html">Last week, I was playing with semantic-release. Giving your CI control over your semantic release. Sweet. I should dedicate a writing on it (to come later). &lt;br/&gt;Nevertheless, I got in a situation that an erroneous version number get released (wrong commit message). Without a major version bump, a breaking change in the lib won't be reflecting (breaking the whole purpose of semantic release). &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Unpublish a "recent" version&lt;/h2&gt;&lt;br/&gt; If you try to unpublish a version just released: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm publish .&lt;br /&gt;+ launcher-demo@5.0.0&lt;br /&gt;$ npm unpublish launcher-demo@5.0.0 &lt;br /&gt;- launcher-demo@5.0.0&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt; It's ok! Pff you can do it. &lt;br/&gt;Now is it possible later to publish the same version? &lt;br/&gt;&lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm publish . &lt;br /&gt;npm ERR! publish Failed PUT 400&lt;br /&gt;npm ERR! code E400&lt;br /&gt;npm ERR! Cannot publish over previously published version "5.0.0". : launcher-demo&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt; It makes sense you can't use the same version, so if you update &lt;code&gt;package.json&lt;/code&gt; to 5.0.1: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm publish .&lt;br /&gt;+ launcher-demo@5.0.1&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt; Just fine! &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Unpublish a "old" version&lt;/h2&gt;&lt;br/&gt; Let's say I want to unpublish a version released last week: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm unpublish launcher-demo@3.2.8&lt;br /&gt;npm ERR! unpublish Failed to update data&lt;br /&gt;npm ERR! code E400&lt;br /&gt;npm ERR! You can no longer unpublish this version. Please deprecate it instead&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;Thanks &lt;code&gt;npm&lt;/code&gt; for your kind suggestion, let try to deprecate it with an short message: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm deprecate launcher-demo@3.2.8 'erronous version'&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;At least now the package is visible as deprecated, trying to pull it will display a deprecate warning. &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm i launcher-demo@3.2.8&lt;br /&gt;npm WARN deprecated launcher-demo@3.2.8: erronous version&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Unpublish policy&lt;/h2&gt;&lt;br/&gt; "Old", "recent" version. What does it all mean? Let's check the &lt;a href="https://www.npmjs.com/policies/unpublish"&gt;npm unpublish policy&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;&lt;div style="border-style: solid;border-color:grey;background: lightgrey;padding:1em"&gt;&lt;strong&gt;Quote:&lt;/strong&gt;If the package is still within the first 72 hours, you should use one of the following from your command line: &lt;br/&gt;&lt;li&gt;&lt;code&gt;npm unpublish &lt;package_name&gt; -f&lt;/code&gt; to remove the entire package thanks to the -f or force flag&lt;&gt;/li &lt;li&gt;&lt;code&gt;npm unpublish &lt;package_name&gt;@&lt;version&gt;&lt;/code&gt; to remove a specific version&lt;/li&gt;&lt;br/&gt;&lt;strong&gt;Some considerations&lt;/strong&gt;: &lt;br/&gt;Once package@version has been used, you can never use it again. You must publish a new version even if you unpublished the old one.&lt;br/&gt;If you entirely unpublish a package, nobody else (even you) will be able to publish a package of that name for 24 hours. &lt;br/&gt;&lt;/div&gt;&lt;br/&gt;After the &lt;a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm"&gt;one-developer-just-broke-Node&lt;/a&gt; buzzy affair in March 2016, the unpublish policies were changed. A 10-lines library used every where should not put the whole JS community down. A step toward more immutability won't arm. &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Where to go from there&lt;/h2&gt;&lt;br/&gt;Error releasing your package? &lt;br/&gt;You've got 72 hours to fix it. &lt;br/&gt;otherwise deprecate it. &lt;br/&gt;Maybe, it's time to automate releasing with your CI. &lt;br/&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-LvL1Uidj5KE/W5pe17y5MgI/AAAAAAAADCw/lYDzG4v5lV0lJaskD8hBzT-cGjyJW2CyQCLcBGAs/s1600/bender.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://4.bp.blogspot.com/-LvL1Uidj5KE/W5pe17y5MgI/AAAAAAAADCw/lYDzG4v5lV0lJaskD8hBzT-cGjyJW2CyQCLcBGAs/s320/bender.png" width="309" height="320" data-original-width="392" data-original-height="406" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Q1Rl7OTT6xo" height="1" width="1" alt=""/&gt;</content><summary>Last week, I was playing with semantic-release. Giving your CI control over your semantic release. Sweet. I should dedicate a writing on it (to come later). Nevertheless, I got in a situation that an erroneous version number get released (wrong commit message). Without a major version bump, a breaking change in the lib won't be reflecting (breaking the whole purpose of semantic release). Unpublish...</summary><dc:creator>Corinne Krych</dc:creator><dc:date>2018-09-13T13:07:00Z</dc:date><feedburner:origLink>http://corinnekrych.blogspot.com/2018/09/unpublish-npm-package.html</feedburner:origLink></entry><entry><title>My trip to JavaZone 2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/F9C-1jF5Gds/my-trip-to-javazone-2018.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Presentation" scheme="searchisko:content:tags" /><category term="speaker" scheme="searchisko:content:tags" /><category term="video" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-my_trip_to_javazone_2018</id><updated>2018-09-13T07:47:30Z</updated><published>2018-09-13T07:36:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="_5pbx userContent _3576" data-ft="{&amp;quot;tn&amp;quot;:&amp;quot;K&amp;quot;}" id="js_11" style="background-color: white; color: #1d2129; font-family: system-ui, -apple-system, system-ui, &amp;quot;.SFNSText-Regular&amp;quot;, sans-serif; font-size: 14px; line-height: 1.38; margin-top: 6px;"&gt;&lt;div class="text_exposed_root text_exposed" id="id_5b9a11b90accf8d76690133" style="display: inline; font-family: inherit;"&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;&lt;span style="font-family: inherit;"&gt;This week I am attending and speaking at the&lt;/span&gt;&lt;span style="font-family: inherit;"&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://2018.javazone.no/"&gt;&lt;span class="_5afx" style="direction: ltr; font-family: inherit;"&gt;&lt;span class="_58cm" style="font-family: inherit;"&gt;JavaZone&lt;/span&gt;&lt;/span&gt;&lt;span style="font-family: inherit;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;span style="font-family: inherit;"&gt;&lt;a href="https://2018.javazone.no/"&gt;2018&lt;/a&gt; conference in Oslo.&lt;/span&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-LwdeyXd17SQ/W5oSYrtH4kI/AAAAAAAABq8/uS8V3H0BxHUgHb3CUl1HtzVDEuR6SL_zgCLcBGAs/s1600/IMG_7007.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1280" data-original-width="960" height="320" src="https://3.bp.blogspot.com/-LwdeyXd17SQ/W5oSYrtH4kI/AAAAAAAABq8/uS8V3H0BxHUgHb3CUl1HtzVDEuR6SL_zgCLcBGAs/s320/IMG_7007.jpg" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;&lt;span style="font-family: inherit;"&gt;I was here last time 7 years ago, so it was good to be back. The weather is very nice with rainbows and unicorns and everything ... well only rainbows.&lt;/span&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-Jag8dLAfCbw/W5oSRS0ZpoI/AAAAAAAABq4/atCkCCHSccEVYNL0dvUsJgZKZ--PN4JOgCLcBGAs/s1600/IMG_7001.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1280" data-original-width="960" height="320" src="https://3.bp.blogspot.com/-Jag8dLAfCbw/W5oSRS0ZpoI/AAAAAAAABq4/atCkCCHSccEVYNL0dvUsJgZKZ--PN4JOgCLcBGAs/s320/IMG_7001.jpg" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;&lt;span style="font-family: inherit;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;As a speaker I was asked to sign the speakers wall, and was given a woollen hat as gift, which will be handy this weekend where I am joining other speakers for a boat trip&amp;nbsp;&lt;span class="_5afx" style="direction: ltr; font-family: inherit;"&gt;&lt;span class="_58cm" style="font-family: inherit;"&gt;JourneyZone&lt;/span&gt;&lt;/span&gt;&amp;nbsp;in northern Norway at&amp;nbsp;&lt;span class="_5afx" style="direction: ltr; font-family: inherit;"&gt;&lt;span class="_58cm" style="font-family: inherit;"&gt;Lofoten&lt;/span&gt;&lt;/span&gt;. T&lt;span class="text_exposed_show" style="display: inline; font-family: inherit;"&gt;hey say the landscape should be spectacular.&lt;/span&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-C7zuwc0DHr8/W5oSf225yCI/AAAAAAAABrA/6YihRYcbNAcGJbXYO4W-JygprxCRUksBQCLcBGAs/s1600/IMG_7011.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="960" data-original-width="1280" height="240" src="https://3.bp.blogspot.com/-C7zuwc0DHr8/W5oSf225yCI/AAAAAAAABrA/6YihRYcbNAcGJbXYO4W-JygprxCRUksBQCLcBGAs/s320/IMG_7011.jpg" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-OBqMZflGyuQ/W5oSfxtJQiI/AAAAAAAABrE/0hP5xDBGYS4KBlGPMyHE9DRvJxj8a39wwCLcBGAs/s1600/IMG_7013.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1280" data-original-width="960" height="320" src="https://3.bp.blogspot.com/-OBqMZflGyuQ/W5oSfxtJQiI/AAAAAAAABrE/0hP5xDBGYS4KBlGPMyHE9DRvJxj8a39wwCLcBGAs/s320/IMG_7013.jpg" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;&lt;span class="text_exposed_show" style="display: inline; font-family: inherit;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-dvrLb3eJlXI/W5oSk7rHe_I/AAAAAAAABrM/YwQlmgFqrqUaH2pH85cSRaukIGl9WrYXwCLcBGAs/s1600/35387807_10156283321721605_3847542608402317312_o.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="939" data-original-width="1600" height="187" src="https://4.bp.blogspot.com/-dvrLb3eJlXI/W5oSk7rHe_I/AAAAAAAABrM/YwQlmgFqrqUaH2pH85cSRaukIGl9WrYXwCLcBGAs/s320/35387807_10156283321721605_3847542608402317312_o.jpg" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;&lt;span class="text_exposed_show" style="display: inline; font-family: inherit;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class="text_exposed_show" style="display: inline; font-family: inherit;"&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;Yesterday evening I was out dining with fellow danish friends Flemming and Anders, whom I know from our little IT-network group called getsmarterdaty.&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-djtJCYPM-Uw/W5oSpR9qa5I/AAAAAAAABrU/SLzQbFzffyowbE4dbhKEUjQI6a6dXDx_QCLcBGAs/s1600/IMG_7002.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1280" data-original-width="962" height="320" src="https://3.bp.blogspot.com/-djtJCYPM-Uw/W5oSpR9qa5I/AAAAAAAABrU/SLzQbFzffyowbE4dbhKEUjQI6a6dXDx_QCLcBGAs/s320/IMG_7002.jpg" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;My talk (&lt;a href="https://2018.javazone.no/program/065eb114-5b6c-4387-a41b-dcb058870704"&gt;Camel microservices with Spring Boot and Kubernetes&lt;/a&gt;) was yesterday at 5pm and its always special to present here at the Spectrum arena in Oslo, as the rooms have very steep seatings so attendees are mostly looking down upon you. The talk is video recorded and will be posted online soon. The &lt;a href="https://github.com/davsclaus/camel-riders-in-the-cloud/tree/javazone"&gt;slides and source-code&lt;/a&gt; is located on my github account.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-Wrk_SZmvl58/W5oWCYx-zEI/AAAAAAAABr0/LqsFkrpPnuIVRZR1KAdjAuuEc0W2f7V-ACLcBGAs/s1600/Dm6T2qIX4AEqbzE.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="900" data-original-width="1600" height="180" src="https://3.bp.blogspot.com/-Wrk_SZmvl58/W5oWCYx-zEI/AAAAAAAABr0/LqsFkrpPnuIVRZR1KAdjAuuEc0W2f7V-ACLcBGAs/s320/Dm6T2qIX4AEqbzE.jpg" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-LOEuTt9d5y4/W5oStnaw0eI/AAAAAAAABrY/Pux1LDQ3aC0wZOx7nPEUQXUzk6G7WGGxACLcBGAs/s1600/IMG_0185.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="956" data-original-width="1280" height="239" src="https://1.bp.blogspot.com/-LOEuTt9d5y4/W5oStnaw0eI/AAAAAAAABrY/Pux1LDQ3aC0wZOx7nPEUQXUzk6G7WGGxACLcBGAs/s320/IMG_0185.jpg" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="font-family: inherit; margin-bottom: 6px; margin-top: 6px;"&gt;The conference hosts about 3000 attendees and is a very well organized event running for 17 years.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="_3x-2" data-ft="{&amp;quot;tn&amp;quot;:&amp;quot;H&amp;quot;}" style="background-color: white; color: #1d2129; font-family: system-ui, -apple-system, system-ui, &amp;quot;.SFNSText-Regular&amp;quot;, sans-serif; font-size: 12px;"&gt;&lt;div data-ft="{&amp;quot;tn&amp;quot;:&amp;quot;H&amp;quot;}" style="font-family: inherit;"&gt;&lt;div class="mtm" style="font-family: inherit; margin-top: 10px;"&gt;&lt;div class="_2a2q _65sr" style="font-family: inherit; height: 430px; margin-left: -12px; margin-right: -12px; overflow: hidden; position: relative; width: 516px;"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-6o6Sk8oNYZQ/W5oSyBgfcnI/AAAAAAAABrg/Q1K6Pie9Iqgb7QP32iZWUxgnu0j1wlyewCLcBGAs/s1600/IMG_7014.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="960" data-original-width="1280" height="240" src="https://3.bp.blogspot.com/-6o6Sk8oNYZQ/W5oSyBgfcnI/AAAAAAAABrg/Q1K6Pie9Iqgb7QP32iZWUxgnu0j1wlyewCLcBGAs/s320/IMG_7014.jpg" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;a ajaxify="https://www.facebook.com/photo.php?fbid=169151280628699&amp;amp;set=pcb.169154413961719&amp;amp;type=3&amp;amp;size=960%2C1280&amp;amp;source=13&amp;amp;player_origin=profile&amp;amp;referrer_profile_id=100026014848069&amp;amp;__xts__%5B0%5D=68.ARDs7OeIrMwWEDdOv4hbJtO8QXIvyVwZzbZy1DxoOmlGiEMX1-1nKkUBNi31WU_RuWzJ8VM_Zhb1bFDv7nxSfy5JS1ONy0cJBgi37lnUf19JzRZDlZ4K1LBYscfKfDmiwiX7ff-pUgJbbuIxl5L4DNYbdYQzx7v6Z9bmCDB67zjeMDtGyjEY&amp;amp;__tn__=HH-R" class="_5dec _xcx" data-ploi="https://scontent-arn2-1.xx.fbcdn.net/v/t1.0-9/41717172_169151287295365_5748056634630864896_o.jpg?_nc_cat=0&amp;amp;oh=1c0cce190ab33441982949595381193a&amp;amp;oe=5C2F3131" data-plsi="https://scontent-arn2-1.xx.fbcdn.net/v/t1.0-9/41665302_169151283962032_1830118232346853376_n.jpg?_nc_cat=0&amp;amp;oh=320fb905cb2176b776095cdca60b91dc&amp;amp;oe=5C3197FB" data-referrerid="100026014848069" data-render-location="timeline" href="https://www.facebook.com/photo.php?fbid=169151280628699&amp;amp;set=pcb.169154413961719&amp;amp;type=3" id="u_0_2r" rel="theater" style="color: #365899; cursor: pointer; display: block; font-family: inherit; height: 257px; left: 0px; position: absolute; text-decoration-line: none; top: 0px; width: 257px;"&gt;&lt;/a&gt;&lt;a ajaxify="https://www.facebook.com/photo.php?fbid=169151280628699&amp;amp;set=pcb.169154413961719&amp;amp;type=3&amp;amp;size=960%2C1280&amp;amp;source=13&amp;amp;player_origin=profile&amp;amp;referrer_profile_id=100026014848069&amp;amp;__xts__%5B0%5D=68.ARDs7OeIrMwWEDdOv4hbJtO8QXIvyVwZzbZy1DxoOmlGiEMX1-1nKkUBNi31WU_RuWzJ8VM_Zhb1bFDv7nxSfy5JS1ONy0cJBgi37lnUf19JzRZDlZ4K1LBYscfKfDmiwiX7ff-pUgJbbuIxl5L4DNYbdYQzx7v6Z9bmCDB67zjeMDtGyjEY&amp;amp;__tn__=HH-R" class="_5dec _xcx" data-ploi="https://scontent-arn2-1.xx.fbcdn.net/v/t1.0-9/41717172_169151287295365_5748056634630864896_o.jpg?_nc_cat=0&amp;amp;oh=1c0cce190ab33441982949595381193a&amp;amp;oe=5C2F3131" data-plsi="https://scontent-arn2-1.xx.fbcdn.net/v/t1.0-9/41665302_169151283962032_1830118232346853376_n.jpg?_nc_cat=0&amp;amp;oh=320fb905cb2176b776095cdca60b91dc&amp;amp;oe=5C3197FB" data-referrerid="100026014848069" data-render-location="timeline" href="https://www.facebook.com/photo.php?fbid=169151280628699&amp;amp;set=pcb.169154413961719&amp;amp;type=3" id="u_0_2r" rel="theater" style="color: #365899; cursor: pointer; display: block; font-family: inherit; height: 257px; left: 0px; position: absolute; text-decoration-line: none; top: 0px; width: 257px;"&gt;&lt;br /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=y_p_6cnTeoQ:YuYYBrRQRVU:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=y_p_6cnTeoQ:YuYYBrRQRVU:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=y_p_6cnTeoQ:YuYYBrRQRVU:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=y_p_6cnTeoQ:YuYYBrRQRVU:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=y_p_6cnTeoQ:YuYYBrRQRVU:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=y_p_6cnTeoQ:YuYYBrRQRVU:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=y_p_6cnTeoQ:YuYYBrRQRVU:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/y_p_6cnTeoQ" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/F9C-1jF5Gds" height="1" width="1" alt=""/&gt;</content><summary>This week I am attending and speaking at the JavaZone 2018 conference in Oslo. I was here last time 7 years ago, so it was good to be back. The weather is very nice with rainbows and unicorns and everything ... well only rainbows. As a speaker I was asked to sign the speakers wall, and was given a woollen hat as gift, which will be handy this weekend where I am joining other speakers for a boat tr...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2018-09-13T07:36:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/y_p_6cnTeoQ/my-trip-to-javazone-2018.html</feedburner:origLink></entry></feed>
